import asyncio
import os
import threading
import time
import wave

import numpy as np
import sounddevice as sd
import soundfile as sf
from google import genai
from google.genai import types


class ChatAudioClient:
    def __init__(
        self, api_key, tools=[], system_instruction="You are a helpful assistant and answer in a friendly tone."
    ):
        self.client = genai.Client(api_key=api_key)
        self.model = "gemini-live-2.5-flash-preview"
        self.tools = [{"function_declarations": tools}]

        self.config = {
            "response_modalities": ["AUDIO"],
            "system_instruction": system_instruction,
            "realtime_input_config": {"automatic_activity_detection": {"disabled": True}},
            "tools": self.tools,
            "speech_config": {"language_code": "ja-JP"},
        }

        self.running = True

        self.audio_buffer = []
        self.is_recording = False
        self.is_listening = False
        self.is_processing = False
        self.is_speaking = False
        self.record_event = threading.Event()

        # UI callback
        self.ui_callback = None

        # Audio settings
        self.sample_rate = 16000
        self.channels = 1
        self.dtype = "int16"  # Native format for Gemini input (16-bit PCM)
        os.makedirs("tmp", exist_ok=True)

    def set_ui_callback(self, callback):
        """UIã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ã‚’è¨­å®š"""
        self.ui_callback = callback

    def notify_ui(self, event, data=None):
        """UIã«çŠ¶æ…‹å¤‰åŒ–ã‚’é€šçŸ¥"""
        if self.ui_callback:
            self.ui_callback(event, data)

    def start_recording(self):
        if not self.is_recording and self.is_listening:
            self.record_event.set()
            self.is_recording = True
            self.notify_ui("recording_started")
            print("ğŸ”´ Recording started.")

    def stop_recording(self):
        if self.is_recording:
            self.record_event.clear()
            self.is_recording = False
            self.notify_ui("recording_stopped")
            print("â¹ï¸ Recording stopped.")

    def listen_to_user(self):
        self.record_event.clear()
        print("ğŸ‘‚ Waiting to record...")
        self.is_listening = True
        self.notify_ui("listening_started")
        self.record_event.wait()
        self.audio_buffer.clear()

        with sd.InputStream(samplerate=self.sample_rate, channels=self.channels, dtype=self.dtype) as stream:
            while self.record_event.is_set():
                data, _ = stream.read(1024)
                self.audio_buffer.append(data)
                time.sleep(0.01)

        print(f"ğŸ™ï¸ Captured {len(self.audio_buffer)} chunks.")
        audio = np.concatenate(self.audio_buffer, axis=0)
        self.is_listening = False
        self.notify_ui("listening_finished")
        # Save a copy for debugging
        wav_path = "tmp/user.wav"
        with wave.open(wav_path, "wb") as wf:
            wf.setnchannels(self.channels)
            wf.setsampwidth(2)  # 16-bit PCM = 2 bytes
            wf.setframerate(self.sample_rate)
            wf.writeframes(audio.tobytes())
        print(f"ğŸ’¾ Saved to {wav_path}")

        # Return raw bytes directly
        return audio.tobytes()

    # override this if you have tools
    def call_tool(self, tool_name, tool_args):
        pass

    async def process_user_input(self, pcm_bytes, session):
        self.is_processing = True
        self.notify_ui("processing_started")

        await session.send_realtime_input(activity_start=types.ActivityStart())
        await session.send_realtime_input(audio=types.Blob(data=pcm_bytes, mime_type="audio/pcm;rate=16000"))
        await session.send_realtime_input(activity_end=types.ActivityEnd())

        print("Sent user audio...")

        """output_path = "tmp/response.wav"
        wf = wave.open(output_path, "wb")
        wf.setnchannels(1)
        wf.setsampwidth(2)
        wf.setframerate(24000)  # Gemini always outputs 24kHz
        """

        async for response in session.receive():
            if response.server_content:
                if response.data is not None:
                    # wf.writeframes(response.data)
                    yield response.data
            elif response.tool_call:
                for fc in response.tool_call.function_calls:
                    result = self.call_tool(fc.name, fc.args)
                    function_response = types.FunctionResponse(
                        id=fc.id,
                        name=fc.name,
                        response={"result": result},  # simple, hard-coded function response
                    )
                    await session.send_tool_response(function_responses=[function_response])

        print("Written response audio...")

        # wf.close()

        # return output_path

    def play_output(self, wav_path):
        print("ğŸ”Š Playing response...")

        data, samplerate = sf.read(wav_path)

        # Play it in full, blocking until complete
        sd.play(data, samplerate)
        sd.wait()

        print("âœ… Playback finished.")

    async def _loop(self):
        queue = asyncio.Queue()
        playback_done_event = asyncio.Event()

        async def playback():
            """
            éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ã—ã€ä¸€å®šã®ãƒ–ãƒ­ãƒƒã‚¯ã‚µã‚¤ã‚ºã§å†ç”Ÿã™ã‚‹ã€‚
            ã“ã‚Œã«ã‚ˆã‚Šã€éŸ³å£°ã®é€”åˆ‡ã‚Œï¼ˆã‚¢ãƒ³ãƒ€ãƒ¼ãƒ©ãƒ³ï¼‰ã‚’é˜²ãã€å†ç”Ÿã‚’å®‰å®šã•ã›ã‚‹ã€‚
            """
            samplerate = 24000
            blocksize = 4800  # 4800ãƒ•ãƒ¬ãƒ¼ãƒ  = 24000 Hzã§0.2ç§’
            block_bytes = blocksize * 2  # int16ã¯2ãƒã‚¤ãƒˆ/ã‚µãƒ³ãƒ—ãƒ«
            write_interval = blocksize / samplerate  # 0.2ç§’

            buffer = bytearray()

            with sd.RawOutputStream(samplerate=samplerate, blocksize=blocksize, channels=1, dtype="int16") as stream:
                while True:
                    try:
                        # æ¬¡ã®ãƒ–ãƒ­ãƒƒã‚¯ã‚’æ›¸ãè¾¼ã‚€ã®ã«ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒãƒãƒƒãƒ•ã‚¡ã«æºœã¾ã‚‹ã¾ã§å¾…ã¤
                        while len(buffer) < block_bytes:
                            # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãã§ã‚­ãƒ¥ãƒ¼ã‹ã‚‰ãƒãƒ£ãƒ³ã‚¯ã‚’å–å¾—
                            chunk = await asyncio.wait_for(queue.get(), timeout=write_interval * 2)

                            if chunk is None:
                                # ç™ºè©±çµ‚äº†ã®åˆå›³(None)ã‚’å—ã‘å–ã£ãŸ
                                # ãƒãƒƒãƒ•ã‚¡ã«æ®‹ã£ã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’å†ç”Ÿã™ã‚‹
                                if buffer:
                                    stream.write(buffer)
                                    buffer.clear()

                                playback_done_event.set()  # ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ã«å†ç”Ÿå®Œäº†ã‚’é€šçŸ¥

                                if not self.running:
                                    return  # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å…¨ä½“ãŒçµ‚äº†ã™ã‚‹å ´åˆã€ã‚¿ã‚¹ã‚¯ã‚’çµ‚äº†
                                else:
                                    # ã‚¢ãƒ—ãƒªã¯ç¶šè¡Œä¸­ã€‚æ¬¡ã®ç™ºè©±ã‚’å¾…ã¤ãŸã‚ã«ãƒ«ãƒ¼ãƒ—ã‚’ç¶šã‘ã‚‹
                                    continue

                            buffer.extend(chunk)

                    except asyncio.TimeoutError:
                        # æ–°ã—ã„éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ãŒæ™‚é–“å†…ã«å±Šã‹ãªã‹ã£ãŸå ´åˆï¼ˆä¾‹ï¼šãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é…å»¶ï¼‰
                        # ãƒãƒƒãƒ•ã‚¡ã«ãƒ‡ãƒ¼ã‚¿ãŒæ®‹ã£ã¦ã„ã‚Œã°ã€ç„¡éŸ³ã§ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã—ã¦å†ç”Ÿã™ã‚‹
                        if buffer:
                            padding = bytes(block_bytes - len(buffer))
                            stream.write(buffer + padding)
                            buffer.clear()
                        # ãƒãƒƒãƒ•ã‚¡ãŒç©ºãªã‚‰ä½•ã‚‚ã—ãªã„ï¼ˆç„¡éŸ³ã‚’å†ç”Ÿã—ç¶šã‘ã‚‹ã“ã¨ã«ãªã‚‹ï¼‰
                        continue

                    # ãƒãƒƒãƒ•ã‚¡ã‹ã‚‰1ãƒ–ãƒ­ãƒƒã‚¯åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ›¸ãå‡ºã™
                    stream.write(buffer[:block_bytes])
                    # æ›¸ãå‡ºã—ãŸåˆ†ã‚’ãƒãƒƒãƒ•ã‚¡ã‹ã‚‰å‰Šé™¤
                    buffer = buffer[block_bytes:]

        # --- ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ— (æœ€åˆã®ã‚³ãƒ¼ãƒ‰ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç¶­æŒ) ---
        async with self.client.aio.live.connect(model=self.model, config=self.config) as session:
            playback_task = asyncio.create_task(playback())

            while self.running:
                playback_done_event.clear()
                print("ğŸŸ¢ Chat audio client running.")

                # å„ã‚µã‚¤ã‚¯ãƒ«é–‹å§‹æ™‚ã«çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
                self.is_processing = False
                self.is_speaking = False

                pcm_bytes = self.listen_to_user()

                # ã“ã“ã§ is_processing = True ã‚’è¨­å®šã™ã‚‹ã®ãŒä¸€èˆ¬çš„
                # self.is_processing = True
                # self.notify_ui("processing_started")

                response_started = False

                async for chunk in self.process_user_input(pcm_bytes, session):
                    if not response_started:
                        # æœ€åˆã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒãƒ£ãƒ³ã‚¯ã‚’å—ã‘å–ã£ãŸã‚‰ç™ºè©±é–‹å§‹
                        self.is_processing = False
                        self.is_speaking = True
                        self.notify_ui("speaking_started")
                        response_started = True

                    await queue.put(chunk)

                # ç™ºè©±ãƒ‡ãƒ¼ã‚¿ã®é€ä¿¡ãŒå®Œäº†ã—ãŸã“ã¨ã‚’playbackã‚¿ã‚¹ã‚¯ã«ä¼ãˆã‚‹
                await queue.put(None)
                # playbackã‚¿ã‚¹ã‚¯ãŒå…¨ã¦ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å†ç”Ÿã—çµ‚ãˆã‚‹ã®ã‚’å¾…ã¤
                await playback_done_event.wait()

                # ç™ºè©±çµ‚äº†ã‚’UIã«é€šçŸ¥
                self.is_speaking = False
                self.notify_ui("speaking_finished")

            # ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ãŸå¾Œã€ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            await queue.put(None)
            await playback_task

    def loop(self):
        asyncio.run(self._loop())

    def run(self):
        thread = threading.Thread(target=self.loop, daemon=True)
        thread.start()
